# -*- coding: utf-8 -*-
"""Train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IwllDIw2LjOU6U-tOjwgkl-ylfoPE6Ns
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from xgboost import XGBRegressor

def create_sequences(data, window, horizon):
    X, y = [], []
    for i in range(len(data) - window - horizon + 1):
        X.append(data[i:i+window])
        y.append(data[i+window+horizon-1][0])
    return np.array(X), np.array(y)


df = pd.read_csv('/content/train.csv')
df['Date'] = pd.to_datetime(df['Order Date'], dayfirst=True)
df = df.sort_values('Date').reset_index(drop=True)

daily_sales = df.groupby('Date')['Sales'].sum().reset_index()
daily_sales.set_index('Date', inplace=True)
daily_sales = daily_sales.asfreq('D')
daily_sales['Sales'] = daily_sales['Sales'].fillna(daily_sales['Sales'].median())
daily_sales['Sales'] = np.log1p(daily_sales['Sales'])
daily_sales.reset_index(inplace=True)


daily_sales['dayofweek'] = daily_sales['Date'].dt.dayofweek
daily_sales['day']       = daily_sales['Date'].dt.day
daily_sales['month']     = daily_sales['Date'].dt.month
daily_sales['quarter']   = daily_sales['Date'].dt.quarter
daily_sales['year']      = daily_sales['Date'].dt.year
daily_sales['is_weekend'] = daily_sales['dayofweek'].isin([5, 6]).astype(int)


features = ['Sales', 'dayofweek', 'day', 'month', 'quarter', 'year', 'is_weekend']
data = daily_sales[features].copy()

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

window_size = 30
horizon = 14

X_lstm, y_lstm = create_sequences(scaled_data, window_size, horizon)
X_lstm = X_lstm[:, :, 0].reshape((X_lstm.shape[0], X_lstm.shape[1], 1))  # Sales only


model_lstm = Sequential()
model_lstm.add(LSTM(64, activation='relu', input_shape=(window_size, 1)))
model_lstm.add(Dense(1))
model_lstm.compile(optimizer='adam', loss='mse')
model_lstm.fit(X_lstm, y_lstm, epochs=20, verbose=0)


lstm_preds = model_lstm.predict(X_lstm).flatten()


X_xgb, y_xgb = create_sequences(scaled_data, window_size, horizon)
X_xgb = X_xgb.reshape((X_xgb.shape[0], X_xgb.shape[1] * X_xgb.shape[2]))

model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1)
model_xgb.fit(X_xgb, y_xgb)

xgb_preds = model_xgb.predict(X_xgb)

hybrid_preds = (lstm_preds + xgb_preds) / 2


def inverse_sales(scaled_sales):
    dummy = np.zeros((len(scaled_sales), scaled_data.shape[1]))
    dummy[:, 0] = scaled_sales
    return scaler.inverse_transform(dummy)[:, 0]

true_values = y_lstm
true_inverse = inverse_sales(true_values)
hybrid_inverse = inverse_sales(hybrid_preds)

mae = mean_absolute_error(true_inverse, hybrid_inverse)
rmse = np.sqrt(mean_squared_error(true_inverse, hybrid_inverse))
r2 = r2_score(true_inverse, hybrid_inverse)
smape = 100 * np.mean(2 * np.abs(hybrid_inverse - true_inverse) / (np.abs(hybrid_inverse) + np.abs(true_inverse)))


print("Final Forecast - Evaluation Metrics:")
print(f"# MAE   : {mae:.2f}")
print(f"# RMSE  : {rmse:.2f}")
print(f"# RÂ²    : {r2:.4f}")
print(f"# SMAPE : {smape:.2f}%")

import os

os.makedirs('models', exist_ok=True)

model_lstm.save('models/lstm_model.keras')

model_xgb.save_model('models/xgb_model.json')

from google.colab import files

files.download('models/lstm_model.keras')

files.download('models/xgb_model.json')

import joblib

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

joblib.dump(scaler, 'models/scaler.save')