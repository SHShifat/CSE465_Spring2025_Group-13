{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc3cGEeuPBbmispQqH+QTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHShifat/CSE465_Spring2025_Group-13/blob/main/LSTM_%26_XGBoost_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9xenCyB6UIs",
        "outputId": "c0af34d9-116b-4948-bab3-8f6511322c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded. Columns: Index(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode',\n",
            "       'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State',\n",
            "       'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category',\n",
            "       'Product Name', 'Sales'],\n",
            "      dtype='object')\n",
            " Part 1 complete — Preprocessing and feature engineering done.\n",
            "        Date     Sales  dayofweek  day  month  quarter  year  is_weekend\n",
            "0 2015-01-03  2.859225          5    3      1        1  2015           1\n",
            "1 2015-01-04  5.666634          6    4      1        1  2015           1\n",
            "2 2015-01-05  3.022179          0    5      1        1  2015           0\n",
            "3 2015-01-06  8.391199          1    6      1        1  2015           0\n",
            "4 2015-01-07  4.479131          2    7      1        1  2015           0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "print(\"Dataset loaded. Columns:\", df.columns)\n",
        "df['Date'] = pd.to_datetime(df['Order Date'], dayfirst=True)\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "daily_sales = df.groupby('Date')['Sales'].sum().reset_index()\n",
        "\n",
        "daily_sales.set_index('Date', inplace=True)\n",
        "daily_sales = daily_sales.asfreq('D')\n",
        "\n",
        "# Median\n",
        "daily_sales['Sales'] = daily_sales['Sales'].fillna(daily_sales['Sales'].median())\n",
        "\n",
        "daily_sales['Sales'] = np.log1p(daily_sales['Sales'])\n",
        "\n",
        "daily_sales.reset_index(inplace=True)\n",
        "\n",
        "# Feature Engineering\n",
        "daily_sales['dayofweek'] = daily_sales['Date'].dt.dayofweek\n",
        "daily_sales['day']       = daily_sales['Date'].dt.day\n",
        "daily_sales['month']     = daily_sales['Date'].dt.month\n",
        "daily_sales['quarter']   = daily_sales['Date'].dt.quarter\n",
        "daily_sales['year']      = daily_sales['Date'].dt.year\n",
        "daily_sales['is_weekend'] = daily_sales['dayofweek'].isin([5, 6]).astype(int)\n",
        "\n",
        "print(\" Part 1 complete — Preprocessing and feature engineering done.\")\n",
        "print(daily_sales.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def create_sequences(data, window, horizon):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window - horizon + 1):\n",
        "        X.append(data[i:i+window])\n",
        "        y.append(data[i+window+horizon-1][0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Features\n",
        "features = ['Sales', 'dayofweek', 'day', 'month', 'quarter', 'year', 'is_weekend']\n",
        "data = daily_sales[features].copy()\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "window_size = 30\n",
        "horizon = 14\n",
        "\n",
        "sales_scaled = scaled_data[:, 0].reshape(-1, 1)\n",
        "X_lstm, y_lstm = create_sequences(scaled_data, window_size, horizon)\n",
        "X_lstm = X_lstm[:, :, 0].reshape((X_lstm.shape[0], X_lstm.shape[1], 1))  # use only Sales for LSTM\n",
        "\n",
        "# LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(64, activation='relu', input_shape=(window_size, 1)))\n",
        "model_lstm.add(Dense(1))\n",
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "model_lstm.fit(X_lstm, y_lstm, epochs=20, verbose=0)\n",
        "\n",
        "# LSTM predictions\n",
        "lstm_preds = model_lstm.predict(X_lstm).flatten()\n",
        "\n",
        "# XGBoost with full multivariate features\n",
        "X_xgb, y_xgb = create_sequences(scaled_data, window_size, horizon)\n",
        "X_xgb = X_xgb.reshape((X_xgb.shape[0], X_xgb.shape[1] * X_xgb.shape[2]))\n",
        "\n",
        "# XGBoost model\n",
        "model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
        "model_xgb.fit(X_xgb, y_xgb)\n",
        "\n",
        "# XGBoost predictions\n",
        "xgb_preds = model_xgb.predict(X_xgb)\n",
        "\n",
        "hybrid_preds = (lstm_preds + xgb_preds) / 2\n",
        "\n",
        "def inverse_sales(scaled_sales):\n",
        "    dummy = np.zeros((len(scaled_sales), scaled_data.shape[1]))\n",
        "    dummy[:, 0] = scaled_sales\n",
        "    return scaler.inverse_transform(dummy)[:, 0]\n",
        "\n",
        "true_values = y_lstm\n",
        "true_inverse = inverse_sales(true_values)\n",
        "hybrid_inverse = inverse_sales(hybrid_preds)\n",
        "\n",
        "mae = mean_absolute_error(true_inverse, hybrid_inverse)\n",
        "rmse = np.sqrt(mean_squared_error(true_inverse, hybrid_inverse))\n",
        "r2 = r2_score(true_inverse, hybrid_inverse)\n",
        "smape = 100 * np.mean(2 * np.abs(hybrid_inverse - true_inverse) / (np.abs(hybrid_inverse) + np.abs(true_inverse)))\n",
        "\n",
        "# Results\n",
        "print(\"Final Forecast - Evaluation Metrics:\")\n",
        "print(f\"# MAE   : {mae:.2f}\")\n",
        "print(f\"# RMSE  : {rmse:.2f}\")\n",
        "print(f\"# R²    : {r2:.4f}\")\n",
        "print(f\"# SMAPE : {smape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmKHHb-A65-W",
        "outputId": "0d0d78c1-da30-40bd-a9cc-03e8354d48d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "Final Forecast - Evaluation Metrics:\n",
            "# MAE   : 0.63\n",
            "# RMSE  : 0.84\n",
            "# R²    : 0.6236\n",
            "# SMAPE : 10.34%\n"
          ]
        }
      ]
    }
  ]
}